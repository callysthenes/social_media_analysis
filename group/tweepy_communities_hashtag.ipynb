{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API keys corresponding to an academic account\n",
    "api_key = \"4OxfMXFZL9yBDYboGSfcjbFsc\"\n",
    "api_secrets = \"Ny9LS2gPD7plQy48c3EpQ3UDvVfqrwvJyZLrAJlgEhQtWz3krW\"\n",
    "access_token =  \"1581220096529375238-2Kt6eULOqBD7EvtpqTf4gvU7n69MZ3\"\n",
    "access_secret = \"7irLEy7IiGfW72gsh895wntdk3n94upoyXtUMGSo98mch\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAPEbiQEAAAAAuuFvB9xcB%2FR4J2RXWNApbAWQ3PY%3DVqvJvvr5WlYDYSfMq5GcZqGGu2gapcfF0ezvJzCWfDaodqSE4L\"\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "    #commented so it doesn't appear in hdfs\n",
    "except:\n",
    "    print('Failed authentication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAAPEbiQEAAAAAuuFvB9xcB%2FR4J2RXWNApbAWQ3PY%3DVqvJvvr5WlYDYSfMq5GcZqGGu2gapcfF0ezvJzCWfDaodqSE4L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Searching Twitter\n",
    "\n",
    "Search for whatever trait your community has in common. In this case, I searched for a popular Twitter hashtag, limiting the results to the 4000 most recent Tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = api.search_tweets(q='#yuan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @globaltimesnews: #GTGraphic: Is the world saying goodbye to #dollar hegemony? More countries turn to #yuan for trade. \n",
      "#China #Brazil #‚Ä¶\n",
      "RT @negocios_tv: √öLTIMA HORA: China y Brasil trasladan el comercio mutuo al Yuan dejando al d√≥lar fuera del mapa\n",
      "\n",
      "https://t.co/grENhAuwWr‚Ä¶\n",
      "RT @NFSC_HAGnews: üî•The world currency war has begun\n",
      "üß®Chinese #Yuan against the #Dollar \n",
      "\n",
      "üì¢Russia's Putin declares to use RMB for foreign tr‚Ä¶\n",
      "RT @globaltimesnews: #GTGraphic: Is the world saying goodbye to #dollar hegemony? More countries turn to #yuan for trade. \n",
      "#China #Brazil #‚Ä¶\n",
      "#BRICS #USD #GBP #SFR #EUR #YUAN https://t.co/Ko4GYoQ0Nk\n",
      "RT @negocios_tv: √öLTIMA HORA: China y Brasil trasladan el comercio mutuo al Yuan dejando al d√≥lar fuera del mapa\n",
      "\n",
      "https://t.co/grENhAuwWr‚Ä¶\n",
      "RT @NievesCPR: #Brasil y #China acordaron ayer en Beijing deshacerse del d√≥lar a favor de sus propias monedas #Yuan y Real Brasile√±o en sus‚Ä¶\n",
      "RT @negocios_tv: √öLTIMA HORA: China y Brasil trasladan el comercio mutuo al Yuan dejando al d√≥lar fuera del mapa\n",
      "\n",
      "https://t.co/grENhAuwWr‚Ä¶\n",
      "RT @globaltimesnews: #Yuan clearing in #trade would be good for #China and #Brazil, as it will effectively reduce the interest rate costs f‚Ä¶\n",
      "RT @negocios_tv: √öLTIMA HORA: China y Brasil trasladan el comercio mutuo al Yuan dejando al d√≥lar fuera del mapa\n",
      "\n",
      "https://t.co/grENhAuwWr‚Ä¶\n",
      "RT @negocios_tv: √öLTIMA HORA: China y Brasil trasladan el comercio mutuo al Yuan dejando al d√≥lar fuera del mapa\n",
      "\n",
      "https://t.co/grENhAuwWr‚Ä¶\n",
      "RT @globaltimesnews: #Yuan clearing in #trade would be good for #China and #Brazil, as it will effectively reduce the interest rate costs f‚Ä¶\n",
      "China makes history with first-ever  LNG transaction settled in yuan. A 65,000-ton shipment from UAE's TotalEnergie‚Ä¶ https://t.co/MdpTvtrFjy\n",
      "‚úîÔ∏è Me gusta del capitalismo: genera crecimiento, trabajo y riqueza.\n",
      "‚ùå no me gusta del capitalismo: privatiza las ga‚Ä¶ https://t.co/Ll8YxB3aPn\n",
      "RT @negocios_tv: √öLTIMA HORA: China y Brasil trasladan el comercio mutuo al Yuan dejando al d√≥lar fuera del mapa\n",
      "\n",
      "https://t.co/grENhAuwWr‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "#show contents of search\n",
    "for tweet in hashtag:\n",
    "    print(tweet.text)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for each field desired from the tweets.\n",
    "sn = []\n",
    "text = []\n",
    "timestamp =[]\n",
    "for tweet in hashtag:\n",
    "    #print (tweet.user.screen_name, tweet.created_at, tweet.text)\n",
    "    timestamp.append(tweet.created_at)\n",
    "    sn.append(tweet.user.screen_name)\n",
    "    text.append(tweet.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to dataframe\n",
    "df = pd.DataFrame()\n",
    "df['timestamp'] = timestamp\n",
    "df['sn'] = sn\n",
    "df['text'] = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for date filtering. Adding an EST time column since chat hosted by people in that time zone.\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['EST'] = df['timestamp'] - pd.Timedelta(hours=5) #Convert to EST\n",
    "\n",
    "df['EST'] = pd.to_datetime(df['EST'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sn</th>\n",
       "      <th>text</th>\n",
       "      <th>EST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-30 16:57:41+00:00</td>\n",
       "      <td>theNoteTaker402</td>\n",
       "      <td>RT @globaltimesnews: #GTGraphic: Is the world ...</td>\n",
       "      <td>2023-03-30 11:57:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-30 16:55:48+00:00</td>\n",
       "      <td>dextergatita</td>\n",
       "      <td>RT @negocios_tv: √öLTIMA HORA: China y Brasil t...</td>\n",
       "      <td>2023-03-30 11:55:48+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-30 16:54:16+00:00</td>\n",
       "      <td>Adeleke10167352</td>\n",
       "      <td>RT @NFSC_HAGnews: üî•The world currency war has ...</td>\n",
       "      <td>2023-03-30 11:54:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-30 16:53:51+00:00</td>\n",
       "      <td>JalifeTime</td>\n",
       "      <td>RT @globaltimesnews: #GTGraphic: Is the world ...</td>\n",
       "      <td>2023-03-30 11:53:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-30 16:52:13+00:00</td>\n",
       "      <td>1BusinessArtist</td>\n",
       "      <td>#BRICS #USD #GBP #SFR #EUR #YUAN https://t.co/...</td>\n",
       "      <td>2023-03-30 11:52:13+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp               sn  \\\n",
       "0 2023-03-30 16:57:41+00:00  theNoteTaker402   \n",
       "1 2023-03-30 16:55:48+00:00     dextergatita   \n",
       "2 2023-03-30 16:54:16+00:00  Adeleke10167352   \n",
       "3 2023-03-30 16:53:51+00:00       JalifeTime   \n",
       "4 2023-03-30 16:52:13+00:00  1BusinessArtist   \n",
       "\n",
       "                                                text                       EST  \n",
       "0  RT @globaltimesnews: #GTGraphic: Is the world ... 2023-03-30 11:57:41+00:00  \n",
       "1  RT @negocios_tv: √öLTIMA HORA: China y Brasil t... 2023-03-30 11:55:48+00:00  \n",
       "2  RT @NFSC_HAGnews: üî•The world currency war has ... 2023-03-30 11:54:16+00:00  \n",
       "3  RT @globaltimesnews: #GTGraphic: Is the world ... 2023-03-30 11:53:51+00:00  \n",
       "4  #BRICS #USD #GBP #SFR #EUR #YUAN https://t.co/... 2023-03-30 11:52:13+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out Tweets in case they are needed later.\n",
    "df.to_csv('yuantweets.csv',index = False,encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of the unique usernames in order to see which users we need to retrieve friends for.\n",
    "allNames = list(df['sn'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Retrieve User Information\n",
    "\n",
    "Now having a list of all of the users we would like to include in our community, we can retrive additional necessary information such as who their are following in order to build our social graph.\n",
    "\n",
    "Note that Twitter does have strict rate limits that can cause problems at this point. A timeout is built into every iteration to minimize this. If problems still occur, you may want to include an intermediate write out on every iteration to maintain what has been captured to that point. The loop can be restarted from the nth value of allNames where a break occurs (i.e. \"for name in allNames[n:]\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dataframe of users that will hold the edge relationships\n",
    "dfUsers = pd.DataFrame()\n",
    "dfUsers['userFromName'] =[]\n",
    "dfUsers['userFromId'] =[]\n",
    "dfUsers['userToId'] = []\n",
    "count = 0 \n",
    "\n",
    "nameCount = len(allNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\n88 - Rate limit exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[65], line 7\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m allNames:\n",
      "\u001b[0;32m      5\u001b[0m     \u001b[39m# Build list of friends    \u001b[39;00m\n",
      "\u001b[0;32m      6\u001b[0m     currentFriends \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m tweepy\u001b[39m.\u001b[39mCursor(api\u001b[39m.\u001b[39mget_friends, screen_name\u001b[39m=\u001b[39mname)\u001b[39m.\u001b[39mpages(\u001b[39m2\u001b[39m):\n",
      "\u001b[0;32m      8\u001b[0m         currentFriends\u001b[39m.\u001b[39mextend(page)\n",
      "\u001b[0;32m      9\u001b[0m     currentId \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mget_user(screen_name\u001b[39m=\u001b[39mname)\u001b[39m.\u001b[39mid\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:110\u001b[0m, in \u001b[0;36mCursorIterator.next\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_cursor \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_tweets \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlimit:\n",
      "\u001b[0;32m    109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "\u001b[1;32m--> 110\u001b[0m data, cursors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod(cursor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_cursor,\n",
      "\u001b[0;32m    111\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs,\n",
      "\u001b[0;32m    112\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n",
      "\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_cursor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_cursor \u001b[39m=\u001b[39m cursors\n",
      "\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\tweepy\\api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n",
      "\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[1;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\tweepy\\api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     44\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_list\n",
      "\u001b[0;32m     45\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_type\n",
      "\u001b[1;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\tweepy\\api.py:2242\u001b[0m, in \u001b[0;36mAPI.get_friends\u001b[1;34m(self, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2207\u001b[0m \u001b[39m@pagination\u001b[39m(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcursor\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;32m   2208\u001b[0m \u001b[39m@payload\u001b[39m(\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlist\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;32m   2209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_friends\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[0;32m   2210\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"get_friends(*, user_id, screen_name, cursor, count, skip_status, \\\u001b[39;00m\n",
      "\u001b[0;32m   2211\u001b[0m \u001b[39m                   include_user_entities)\u001b[39;00m\n",
      "\u001b[0;32m   2212\u001b[0m \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   2240\u001b[0m \u001b[39m    https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/follow-search-get-users/api-reference/get-friends-list\u001b[39;00m\n",
      "\u001b[0;32m   2241\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 2242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(\n",
      "\u001b[0;32m   2243\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfriends/list\u001b[39m\u001b[39m'\u001b[39m, endpoint_parameters\u001b[39m=\u001b[39m(\n",
      "\u001b[0;32m   2244\u001b[0m             \u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscreen_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcursor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mskip_status\u001b[39m\u001b[39m'\u001b[39m,\n",
      "\u001b[0;32m   2245\u001b[0m             \u001b[39m'\u001b[39m\u001b[39minclude_user_entities\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;32m   2246\u001b[0m         ), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n",
      "\u001b[0;32m   2247\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\tweepy\\api.py:269\u001b[0m, in \u001b[0;36mAPI.request\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    267\u001b[0m     \u001b[39mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m429\u001b[39m:\n",
      "\u001b[1;32m--> 269\u001b[0m     \u001b[39mraise\u001b[39;00m TooManyRequests(resp)\n",
      "\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m500\u001b[39m:\n",
      "\u001b[0;32m    271\u001b[0m     \u001b[39mraise\u001b[39;00m TwitterServerError(resp)\n",
      "\n",
      "\u001b[1;31mTooManyRequests\u001b[0m: 429 Too Many Requests\n",
      "88 - Rate limit exceeded"
     ]
    }
   ],
   "source": [
    "\n",
    "# The choice to retrieve friends (who the user is following) rather than followers is intentional.\n",
    "# Either would work. However, many Twitter users follow fewer users than are following them, especially the most popular accounts. \n",
    "# This reduces the number of very large calls to Twitter API, which seemed to cause problems.\n",
    "for name in allNames:\n",
    "    # Build list of friends    \n",
    "    currentFriends = []\n",
    "    for page in tweepy.Cursor(api.get_friends, screen_name=name).pages(2):\n",
    "        currentFriends.extend(page)\n",
    "    currentId = api.get_user(screen_name=name).id\n",
    "    currentId = [currentId] * len(currentFriends)\n",
    "    currentName = [name] * len(currentFriends)   \n",
    "    dfTemp = pd.DataFrame()\n",
    "    dfTemp['userFromName'] = currentName\n",
    "    dfTemp['userFromId'] = currentId\n",
    "    dfTemp['userToId'] = currentFriends\n",
    "    dfUsers = pd.concat([dfUsers,dfTemp])\n",
    "    time.sleep(70) # avoids hitting Twitter rate limit\n",
    "    # Progress bar to track approximate progress\n",
    "    count +=1\n",
    "    per = round(count*100.0/nameCount,1)\n",
    "    sys.stdout.write(\"\\rTwitter call %s%% complete.\" % per)\n",
    "    sys.stdout.flush()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['userFromName', 'userFromId'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[63], line 7\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m dfChat \u001b[39m=\u001b[39m dfUsers[dfUsers[\u001b[39m'\u001b[39m\u001b[39muserToId\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x \u001b[39min\u001b[39;00m fromId)]\n",
      "\u001b[0;32m      6\u001b[0m \u001b[39m# No more Twitter API lookups are necessary. Create a lookup table that we will use to get the verify the userToName\u001b[39;00m\n",
      "\u001b[1;32m----> 7\u001b[0m dfLookup \u001b[39m=\u001b[39m dfChat[[\u001b[39m'\u001b[39;49m\u001b[39muserFromName\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39muserFromId\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n",
      "\u001b[0;32m      8\u001b[0m dfLookup \u001b[39m=\u001b[39m dfLookup\u001b[39m.\u001b[39mdrop_duplicates()\n",
      "\u001b[0;32m      9\u001b[0m dfLookup\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39muserToName\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muserToId\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[0;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[0;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n",
      "\u001b[0;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n",
      "\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n",
      "\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n",
      "\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n",
      "\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n",
      "\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n",
      "\u001b[0;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n",
      "\u001b[0;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "\u001b[1;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n",
      "\u001b[0;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['userFromName', 'userFromId'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "# Again, to limit the number of calls to Twitter API, just do lookups on followers that connect to those in our user group.\n",
    "# We are not interested in \"friends\" that are not part of this community.\n",
    "fromId = dfUsers['userFromId'].unique()\n",
    "dfChat = dfUsers[dfUsers['userToId'].apply(lambda x: x in fromId)]\n",
    "\n",
    "# No more Twitter API lookups are necessary. Create a lookup table that we will use to get the verify the userToName\n",
    "dfLookup = dfChat[['userFromName','userFromId']]\n",
    "dfLookup = dfLookup.drop_duplicates()\n",
    "dfLookup.columns = ['userToName','userToId']\n",
    "dfCommunity = dfUsers.merge(dfLookup, on='userToId')\n",
    "\n",
    "dfCommunity.to_csv('dfCommunity.csv',index = False,encoding='utf-8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
